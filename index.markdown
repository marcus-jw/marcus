---
layout: home
---

# Welcome to My Website

I'm Marcus Williams, an AI Alignment Engineer and Research Scholar at MATS. My work focuses on improving the safety and reliability of AI systems.

## Recent Projects

- [Targeted Manipulation and Deception in LLMs](https://github.com/marcus-jw/Targeted-Manipulation-and-Deception-in-LLMs)
- [Multi-Objective Reinforcement Learning from AI Feedback](https://github.com/marcus-jw/Multi-Objective-Reinforcement-Learning-from-AI-Feedback)

## Latest Publications

- [On The Expressivity of Objective-Specification Formalisms in RL](https://arxiv.org/abs/2310.11840) (ICLR 2024)
- [Multi-objective Reinforcement learning from AI Feedback](https://arxiv.org/abs/2406.07295) (Pending)

[View my full CV](/cv/)
